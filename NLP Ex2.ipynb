{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11060,
     "status": "ok",
     "timestamp": 1672978065405,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "minrT-nqsCsi",
    "outputId": "0bbc7353-8d33-4bbe-951e-5a7d50126f81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\t\n",
    "import spacy\t\n",
    "nltk.download('punkt')\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 14635,
     "status": "ok",
     "timestamp": 1672978086870,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "a1QNtBRhsTUE"
   },
   "outputs": [],
   "source": [
    "news_data = fetch_20newsgroups(subset='all')\t\n",
    "articles = news_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1672978094727,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "N7I9FWUfseDj",
    "outputId": "ba5126d0-28fa-4a3c-978a-862ac65f1377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1672978820275,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "Jb_fdsGzsm7Z"
   },
   "outputs": [],
   "source": [
    "# Import word and sentence tokenizers\t\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1672978873649,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "MG9wsTWOtPpT",
    "outputId": "09acd552-cd77-478c-888a-b50ad178cc47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', ':', 'Mamatha', 'Devineni', 'Ratnam', '<', 'mr47+', '@', 'andrew.cmu.edu', '>', 'Subject', ':', 'Pens', 'fans', 'reactions', 'Organization', ':', 'Post', 'Office', ',', 'Carnegie', 'Mellon', ',', 'Pittsburgh', ',', 'PA', 'Lines', ':', '12', 'NNTP-Posting-Host', ':', 'po4.andrew.cmu.edu', 'I', 'am', 'sure', 'some', 'bashers', 'of', 'Pens', 'fans', 'are', 'pretty', 'confused', 'about', 'the', 'lack', 'of', 'any', 'kind', 'of', 'posts', 'about', 'the', 'recent', 'Pens', 'massacre', 'of', 'the', 'Devils', '.', 'Actually', ',', 'I', 'am', 'bit', 'puzzled', 'too', 'and', 'a', 'bit', 'relieved', '.', 'However', ',', 'I', 'am', 'going', 'to', 'put', 'an', 'end', 'to', 'non-PIttsburghers', \"'\", 'relief', 'with', 'a', 'bit', 'of', 'praise', 'for', 'the', 'Pens', '.', 'Man', ',', 'they', 'are', 'killing', 'those', 'Devils', 'worse', 'than', 'I', 'thought', '.', 'Jagr', 'just', 'showed', 'you', 'why', 'he', 'is', 'much', 'better', 'than', 'his', 'regular', 'season', 'stats', '.', 'He', 'is', 'also', 'a', 'lot', 'fo', 'fun', 'to', 'watch', 'in', 'the', 'playoffs', '.', 'Bowman', 'should', 'let', 'JAgr', 'have', 'a', 'lot', 'of', 'fun', 'in', 'the', 'next', 'couple', 'of', 'games', 'since', 'the', 'Pens', 'are', 'going', 'to', 'beat', 'the', 'pulp', 'out', 'of', 'Jersey', 'anyway', '.', 'I', 'was', 'very', 'disappointed', 'not', 'to', 'see', 'the', 'Islanders', 'lose', 'the', 'final', 'regular', 'season', 'game', '.', 'PENS', 'RULE', '!', '!', '!']\n",
      "['From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\\nSubject: Pens fans reactions\\nOrganization: Post Office, Carnegie Mellon, Pittsburgh, PA\\nLines: 12\\nNNTP-Posting-Host: po4.andrew.cmu.edu\\n\\n\\n\\nI am sure some bashers of Pens fans are pretty confused about the lack\\nof any kind of posts about the recent Pens massacre of the Devils.', 'Actually,\\nI am  bit puzzled too and a bit relieved.', \"However, I am going to put an end\\nto non-PIttsburghers' relief with a bit of praise for the Pens.\", 'Man, they\\nare killing those Devils worse than I thought.', 'Jagr just showed you why\\nhe is much better than his regular season stats.', 'He is also a lot\\nfo fun to watch in the playoffs.', 'Bowman should let JAgr have a lot of\\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway.', 'I was very disappointed not to see the Islanders lose the final\\nregular season game.', 'PENS RULE!!', '!']\n"
     ]
    }
   ],
   "source": [
    "first_article=articles[0]\n",
    "# Generate Word tokens\t\n",
    "word_tokens = word_tokenize(first_article)\n",
    "\n",
    "# Generate Sentence Tokens\t\n",
    "sentence_tokens = sent_tokenize(first_article)\t\n",
    "\n",
    "# Print the results\t\n",
    "print(word_tokens)\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1672979549688,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "9IS2xB41uYnP"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1672979557216,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "Z6ZjT46xv7s6",
    "outputId": "04dc1c91-c87f-4aed-ce54-de1c4aca843c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# Acquire the stop words\t\n",
    "english_stw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1672979563933,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "Gt37mxU2wJJ3",
    "outputId": "6b60ee5b-32c5-4076-bded-5d28958ea901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', ':', 'Mamatha', 'Devineni', 'Ratnam', '<', 'mr47+', '@', 'andrew.cmu.edu', '>', 'Subject', ':', 'Pens', 'fans', 'reactions', 'Organization', ':', 'Post', 'Office', ',', 'Carnegie', 'Mellon', ',', 'Pittsburgh', ',', 'PA', 'Lines', ':', '12', 'NNTP-Posting-Host', ':', 'po4.andrew.cmu.edu', 'I', 'sure', 'bashers', 'Pens', 'fans', 'pretty', 'confused', 'lack', 'kind', 'posts', 'recent', 'Pens', 'massacre', 'Devils', '.', 'Actually', ',', 'I', 'bit', 'puzzled', 'bit', 'relieved', '.', 'However', ',', 'I', 'going', 'put', 'end', 'non-PIttsburghers', \"'\", 'relief', 'bit', 'praise', 'Pens', '.', 'Man', ',', 'killing', 'Devils', 'worse', 'I', 'thought', '.', 'Jagr', 'showed', 'much', 'better', 'regular', 'season', 'stats', '.', 'He', 'also', 'lot', 'fo', 'fun', 'watch', 'playoffs', '.', 'Bowman', 'let', 'JAgr', 'lot', 'fun', 'next', 'couple', 'games', 'since', 'Pens', 'going', 'beat', 'pulp', 'Jersey', 'anyway', '.', 'I', 'disappointed', 'see', 'Islanders', 'lose', 'final', 'regular', 'season', 'game', '.', 'PENS', 'RULE', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "non_stop_words = [word for word in word_tokens if word not in english_stw]\t\n",
    "\n",
    "# Show the final stop words\t\n",
    "print(non_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1672980513072,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "hPdS2TO1ylmB",
    "outputId": "bf2f25c4-d747-4866-c313-eea8d58a0b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', 'Mamatha', 'Devineni', 'Ratnam', 'mr47+', 'andrew.cmu.edu', 'Subject', 'Pens', 'fans', 'reactions', 'Organization', 'Post', 'Office', 'Carnegie', 'Mellon', 'Pittsburgh', 'PA', 'Lines', '12', 'NNTP-Posting-Host', 'po4.andrew.cmu.edu', 'I', 'sure', 'bashers', 'Pens', 'fans', 'pretty', 'confused', 'lack', 'kind', 'posts', 'recent', 'Pens', 'massacre', 'Devils', 'Actually', 'I', 'bit', 'puzzled', 'bit', 'relieved', 'However', 'I', 'going', 'put', 'end', 'non-PIttsburghers', 'relief', 'bit', 'praise', 'Pens', 'Man', 'killing', 'Devils', 'worse', 'I', 'thought', 'Jagr', 'showed', 'much', 'better', 'regular', 'season', 'stats', 'He', 'also', 'lot', 'fo', 'fun', 'watch', 'playoffs', 'Bowman', 'let', 'JAgr', 'lot', 'fun', 'next', 'couple', 'games', 'since', 'Pens', 'going', 'beat', 'pulp', 'Jersey', 'anyway', 'I', 'disappointed', 'see', 'Islanders', 'lose', 'final', 'regular', 'season', 'game', 'PENS', 'RULE']\n"
     ]
    }
   ],
   "source": [
    "import string\t\n",
    "without_punct = list(filter(lambda word: word not in string.punctuation, non_stop_words))\n",
    "print(without_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1672980520304,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "S__Ux41PzJ09",
    "outputId": "db7455a5-f9b7-446d-891a-3fe6c5e539bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Import the Lemmatizer module\t\n",
    "from nltk.stem import WordNetLemmatizer\t\n",
    "\n",
    "# Download wordnet lexicon database\t\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Instanciate Lemmatizer\t\n",
    "my_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1672980533100,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "UTYeAJlS299c"
   },
   "outputs": [],
   "source": [
    "#Import the Stemmer module\t\n",
    "from nltk.stem.porter import PorterStemmer\t\n",
    "\n",
    "# Create instance of stemmer\t\n",
    "my_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1672980639951,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "4MxpieiX3EdY",
    "outputId": "cdbe2dc5-3b8b-4f64-8c46-62781d2d0a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: This --->: thi\n",
      "Word: thing --->: thing\n",
      "Word: really --->: realli\n",
      "Word: confuses. --->: confuses.\n",
      "Word: But --->: but\n",
      "Word: you --->: you\n",
      "Word: confuse --->: confus\n",
      "Word: me --->: me\n",
      "Word: more --->: more\n",
      "Word: than --->: than\n",
      "Word: what --->: what\n",
      "Word: is --->: is\n",
      "Word: written --->: written\n",
      "Word: here. --->: here.\n",
      "Word: So --->: so\n",
      "Word: stay --->: stay\n",
      "Word: away --->: away\n",
      "Word: from --->: from\n",
      "Word: explaining --->: explain\n",
      "Word: things --->: thing\n",
      "Word: you --->: you\n",
      "Word: do --->: do\n",
      "Word: not --->: not\n",
      "Word: understand. --->: understand.\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"This thing really confuses.\t \n",
    "                 But you confuse me more than what is written here.\t  \n",
    "                 So stay away from explaining things you do not understand. \t\n",
    "              \"\"\"\n",
    "\n",
    "\n",
    "def stem_words(sentence, model=my_stemmer):\t\n",
    "  \n",
    "    for word in sentence.split():\t\n",
    "      stem = model.stem(word)\t\n",
    "      print(\"Word: {} --->: {}\".format(word, stem))\n",
    "\n",
    "\n",
    "# Run the stemming\t\n",
    "stem_words(sample_text, model=my_stemmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2274,
     "status": "ok",
     "timestamp": 1672980730495,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "GVv1D77Y3UWF",
    "outputId": "0101c02c-5fef-42d9-aa07-283fd24f250c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: This --->: This\n",
      "Word: thing --->: thing\n",
      "Word: really --->: really\n",
      "Word: confuses. --->: confuses.\n",
      "Word: But --->: But\n",
      "Word: you --->: you\n",
      "Word: confuse --->: confuse\n",
      "Word: me --->: me\n",
      "Word: more --->: more\n",
      "Word: than --->: than\n",
      "Word: what --->: what\n",
      "Word: is --->: is\n",
      "Word: written --->: written\n",
      "Word: here. --->: here.\n",
      "Word: So --->: So\n",
      "Word: stay --->: stay\n",
      "Word: away --->: away\n",
      "Word: from --->: from\n",
      "Word: explaining --->: explaining\n",
      "Word: things --->: thing\n",
      "Word: you --->: you\n",
      "Word: do --->: do\n",
      "Word: not --->: not\n",
      "Word: understand. --->: understand.\n"
     ]
    }
   ],
   "source": [
    "def lemmatize_words(sentence, model = my_lemmatizer):\t\n",
    "\n",
    "    for word in sentence.split():\t\n",
    "      lemma = model.lemmatize(word)\t\n",
    "      print(\"Word: {} --->: {}\".format(word, lemma))\n",
    "lemmatize_words(sample_text, model = my_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1672980855257,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "1lEFn2PO5eDR",
    "outputId": "a68ee996-39b6-4f14-f0cf-269d9889ec8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('From', 'IN'), ('Mamatha', 'NNP'), ('Devineni', 'NNP'), ('Ratnam', 'NNP'), ('mr47+', 'VBZ'), ('andrew.cmu.edu', 'NN'), ('Subject', 'NNP'), ('Pens', 'NNP'), ('fans', 'NNS'), ('reactions', 'NNS'), ('Organization', 'NNP'), ('Post', 'NNP'), ('Office', 'NNP'), ('Carnegie', 'NNP'), ('Mellon', 'NNP'), ('Pittsburgh', 'NNP'), ('PA', 'NNP'), ('Lines', 'VBZ'), ('12', 'CD'), ('NNTP-Posting-Host', 'JJ'), ('po4.andrew.cmu.edu', 'NN'), ('I', 'PRP'), ('sure', 'VBP'), ('bashers', 'NNS'), ('Pens', 'NNPS'), ('fans', 'NNS'), ('pretty', 'RB'), ('confused', 'JJ'), ('lack', 'NN'), ('kind', 'NN'), ('posts', 'VBZ'), ('recent', 'JJ'), ('Pens', 'NNP'), ('massacre', 'NN'), ('Devils', 'NNP'), ('Actually', 'NNP'), ('I', 'PRP'), ('bit', 'VBP'), ('puzzled', 'JJ'), ('bit', 'NN'), ('relieved', 'VBD'), ('However', 'RB'), ('I', 'PRP'), ('going', 'VBG'), ('put', 'JJ'), ('end', 'VB'), ('non-PIttsburghers', 'NNS'), ('relief', 'JJ'), ('bit', 'NN'), ('praise', 'NN'), ('Pens', 'NNP'), ('Man', 'NNP'), ('killing', 'VBG'), ('Devils', 'NNP'), ('worse', 'NN'), ('I', 'PRP'), ('thought', 'VBD'), ('Jagr', 'NNP'), ('showed', 'VBD'), ('much', 'JJ'), ('better', 'JJR'), ('regular', 'JJ'), ('season', 'NN'), ('stats', 'NNS'), ('He', 'PRP'), ('also', 'RB'), ('lot', 'VBD'), ('fo', 'JJ'), ('fun', 'NN'), ('watch', 'NN'), ('playoffs', 'NNS'), ('Bowman', 'NNP'), ('let', 'VBP'), ('JAgr', 'NNP'), ('lot', 'NN'), ('fun', 'NN'), ('next', 'JJ'), ('couple', 'NN'), ('games', 'NNS'), ('since', 'IN'), ('Pens', 'NNP'), ('going', 'VBG'), ('beat', 'NN'), ('pulp', 'NN'), ('Jersey', 'NNP'), ('anyway', 'RB'), ('I', 'PRP'), ('disappointed', 'VBD'), ('see', 'NN'), ('Islanders', 'NNPS'), ('lose', 'VBP'), ('final', 'JJ'), ('regular', 'NN'), ('season', 'NN'), ('game', 'NN'), ('PENS', 'NNP'), ('RULE', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "# Import the module\t\n",
    "from nltk.tag import pos_tag\t\n",
    "\n",
    "# Download the tagger\t\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Perform the post tagging\t\n",
    "tagged_tokens = pos_tag(without_punct)\t\n",
    "\n",
    "# Show the final result\t\n",
    "print(tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2055,
     "status": "ok",
     "timestamp": 1672984693880,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "qBhMRaHqR01O",
    "outputId": "23b3e854-df0d-4421-d070-cf55751cff8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Python is an interpreted, high-level and general-purpose programming language., Pythons design philosophy emphasizes code readability with its notableuse of significant indentation., Its language constructs and object-oriented approachaim to help programmers write clear and logical code for small and large-scale projects]\n",
      "Python\n",
      "is\n",
      "an\n",
      "interpreted\n",
      ",\n",
      "high\n",
      "-\n",
      "level\n",
      "and\n",
      "general\n",
      "-\n",
      "purpose\n",
      "programming\n",
      "language\n",
      ".\n",
      "Pythons\n",
      "design\n",
      "philosophy\n",
      "emphasizes\n",
      "code\n",
      "readability\n",
      "with\n",
      "its\n",
      "notableuse\n",
      "of\n",
      "significant\n",
      "indentation\n",
      ".\n",
      "Its\n",
      "language\n",
      "constructs\n",
      "and\n",
      "object\n",
      "-\n",
      "oriented\n",
      "approachaim\n",
      "to\n",
      "help\n",
      "programmers\n",
      "write\n",
      "clear\n",
      "and\n",
      "logical\n",
      "code\n",
      "for\n",
      "small\n",
      "and\n",
      "large\n",
      "-\n",
      "scale\n",
      "projects\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/spacy/displacy/__init__.py:206: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Python is an interpreted, high-level and general-purpose programming language.Pythons design philosophy emphasizes code readability with its notableuse of significant indentation. Its language constructs and object-oriented approachaim to help programmers write clear and logical code for small and large-scale projects</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy import tokenizer\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    " \n",
    "#Load the text and process it\n",
    "# I copied the text from python wiki\n",
    "text =(\"Python is an interpreted, high-level and general-purpose programming language.\" \n",
    "\"Pythons design philosophy emphasizes code readability with its notable\" \n",
    "\"use of significant indentation. Its language constructs and object-oriented approach\" \n",
    "\"aim to help programmers write clear and logical code for small and large-scale projects\")\n",
    "# text2 = # copy the paragraphs from  https://www.python.org/doc/essays/\n",
    "doc = nlp(text)\n",
    "#doc2 = nlp(text2)\n",
    "sentences = list(doc.sents)\n",
    "print(sentences)\n",
    "# tokenization\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "# print entities\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(ents)\n",
    "# now we use displaycy function on doc2\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8263,
     "status": "ok",
     "timestamp": 1672984722769,
     "user": {
      "displayName": "Bhimsen Joshi",
      "userId": "13146763517110248705"
     },
     "user_tz": -330
    },
    "id": "2lJx6JTMp9Tu",
    "outputId": "7808aba4-b754-427d-fb4c-9db340918cf7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/state_union.zip.\n"
     ]
    }
   ],
   "source": [
    "# import modules and download packages\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('state_union')\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    " \n",
    "# process the text and print Named entities\n",
    "# tokenization\n",
    "train_text = state_union.raw()\n",
    " \n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "# function\n",
    "def get_named_entity():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            namedEnt = nltk.ne_chunk(tagged, binary=False)\n",
    "            namedEnt.draw()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "get_named_entity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMqgQOGUKEshx041o86AJGw",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
